{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1984234-8c19-43a2-a1bd-a6568980282e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bedrock Claude使用langchain agent搜索 YouTube 视频"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04d1882-5917-404e-b89d-4674f5b88ff5",
   "metadata": {},
   "source": [
    "## 安装依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4054405-36f4-4995-9aad-bd60910f8374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain langchain_community langchain_core youtube_search --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63500490-01b6-4980-899c-b73d6add54a0",
   "metadata": {},
   "source": [
    "## 设置anthropic function 模版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da5e10-a074-4186-9522-929bb8a781db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.utils.openai_functions import (\n",
    "    FunctionDescription,\n",
    ")\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "\n",
    "def format_tool_to_anthropic_function(tool: BaseTool) -> FunctionDescription:\n",
    "    \"\"\"Format tool into the Bedrock function API.\"\"\"\n",
    "    return f\"\"\"\n",
    "<tool_description>\n",
    "<tool_name>{tool.name}</tool_name>\n",
    "<description>\n",
    "{tool.description}\n",
    "<parameters>\n",
    "<parameter>\n",
    "<name>__arg1</name>\n",
    "<type>string</type>\n",
    "<description>The input of the function</description>\n",
    "</parameter>\n",
    "</parameters>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80fc1a3-bf49-464c-9070-439deb9b5dd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Claude 函数模板解析器AnthropicFunctionsAgentOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24266968-4f29-4261-828d-a89e7ae04633",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from json import JSONDecodeError\n",
    "from typing import List, Union\n",
    "from langchain_core.agents import AgentAction, AgentActionMessageLog, AgentFinish\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_core.outputs import ChatGeneration, Generation\n",
    "from langchain.agents.agent import AgentOutputParser\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    HumanMessage\n",
    ")\n",
    "\n",
    "\n",
    "class AnthropicFunctionsAgentOutputParser(AgentOutputParser):\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_function_call(full_text):\n",
    "        # Encontrar o início e o fim da string XML\n",
    "        if \"function_calls\" not in full_text:\n",
    "            return None\n",
    "\n",
    "        start = full_text.find(\"<function_calls>\")\n",
    "        end = full_text.find(\"</function_calls>\") + len(\"</function_calls>\")\n",
    "\n",
    "        # Extrair a string XML\n",
    "        xml_string = full_text[start:end]\n",
    "\n",
    "        # Análise da string XML\n",
    "        root = ET.fromstring(xml_string)\n",
    "\n",
    "        # Encontrar o nome da ferramenta\n",
    "        tool_name = root.find(\".//tool_name\").text\n",
    "\n",
    "        # Construir o dicionário de parâmetros\n",
    "        parameters = {}\n",
    "        for param in root.findall(\".//parameters/*\"):\n",
    "            parameters[param.tag] = param.text\n",
    "\n",
    "        # Construir o dicionário final com nome e parâmetros\n",
    "        return {\n",
    "            \"name\": tool_name,\n",
    "            \"arguments\": parameters\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"openai-functions-agent\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_ai_message(message: BaseMessage) -> Union[AgentAction, AgentFinish]:\n",
    "        \"\"\"Parse an AI message.\"\"\"\n",
    "        if not isinstance(message, AIMessage):\n",
    "            raise TypeError(f\"Expected an AI message got {type(message)}\")\n",
    "\n",
    "        function_call = AnthropicFunctionsAgentOutputParser._extract_function_call(message.content)\n",
    "\n",
    "        if function_call and 'Final Answer:' not in message.content:\n",
    "            function_name = function_call[\"name\"]\n",
    "            try:\n",
    "                if len(function_call.keys()) == 0:\n",
    "                    # OpenAI returns an empty string for functions containing no args\n",
    "                    _tool_input = {}\n",
    "                else:\n",
    "                    # otherwise it returns a json object\n",
    "                    _tool_input = function_call[\"arguments\"]\n",
    "            except JSONDecodeError:\n",
    "                raise OutputParserException(\n",
    "                    f\"Could not parse tool input: {function_call} because \"\n",
    "                    f\"the `arguments` is not valid JSON.\"\n",
    "                )\n",
    "\n",
    "            if \"__arg1\" in _tool_input.keys():\n",
    "                tool_input = _tool_input[\"__arg1\"]\n",
    "            else:\n",
    "                tool_input = _tool_input\n",
    "\n",
    "            content_msg = f\"responded: {message.content}\\n\" if message.content else \"\\n\"\n",
    "            log = f\"\\nInvoking: `{function_name}` with `{tool_input}`\\n{content_msg}\\n\"\n",
    "            return AgentActionMessageLog(\n",
    "                tool=function_name,\n",
    "                tool_input=tool_input,\n",
    "                log=log,\n",
    "                message_log=[message],\n",
    "            )\n",
    "\n",
    "        start = message.content.find(\"Final Answer:\")\n",
    "\n",
    "        return AgentFinish(\n",
    "            return_values={\"output\": message.content[start:]}, log=str(message.content)\n",
    "        )\n",
    "\n",
    "    def parse_result(\n",
    "            self, result: List[Generation], *, partial: bool = False\n",
    "    ) -> Union[AgentAction, AgentFinish]:\n",
    "        if not isinstance(result[0], ChatGeneration):\n",
    "            raise ValueError(\"This output parser only works on ChatGeneration output\")\n",
    "        message = result[0].message\n",
    "        return self._parse_ai_message(message)\n",
    "\n",
    "    def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\n",
    "        raise ValueError(\"Can only parse messages\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab84ab69-49f3-4546-870b-a128a13177a5",
   "metadata": {},
   "source": [
    "## 加载Claude大模型并且设置prompt 模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ed90e-06e8-4e3d-ba7c-3cc91914cf8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a helfull assistant, your task is help the user achieve is goal.\n",
    "In this environment you have access to a set of tools you can use to answer the user's question.\n",
    "Use them in a smart way to fullfill our objetives. Always consider the history of previous steps to ensure a continuos progress towards the objetive.\n",
    "When you have the answer for the user, always answer it in this forma bellow:\n",
    "Final Answer: answer to user\n",
    "\n",
    "\n",
    "You may call them like this. Only invoke one function at a time and wait for the results before invoking another function:\n",
    "<function_calls>\n",
    "<invoke>\n",
    "<tool_name>$TOOL_NAME</tool_name>\n",
    "<parameters>\n",
    "<$PARAMETER_NAME>$PARAMETER_VALUE</$PARAMETER_NAME>\n",
    "...\n",
    "</parameters>\n",
    "</invoke>\n",
    "</function_calls>\n",
    "\n",
    "Here are the tools available:\n",
    "<tools>\n",
    "{tools_string}\n",
    "</tools>\n",
    "\n",
    "\n",
    "User:\n",
    "{input}\n",
    "\n",
    "<history>\n",
    "{agent_scratchpad}\n",
    "</history>\n",
    "\"\"\"\n",
    "\n",
    "llm = BedrockChat(model_id=\"anthropic.claude-v2:1\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", prompt_template),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069ce40-67d2-498c-a19f-31fedf964619",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 构建 Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc2e9b-80e5-402f-843b-297246752e41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.tools.youtube.search import YouTubeSearchTool\n",
    "from langchain.agents.format_scratchpad.openai_functions import (\n",
    "    format_to_openai_function_messages,\n",
    ")\n",
    "\n",
    "agent = (\n",
    "        RunnablePassthrough.assign(\n",
    "            agent_scratchpad=lambda x: format_to_openai_function_messages(\n",
    "                x[\"intermediate_steps\"]\n",
    "            )\n",
    "        )\n",
    "        | prompt\n",
    "        | llm\n",
    "        | AnthropicFunctionsAgentOutputParser()\n",
    ")\n",
    "\n",
    "tools = [YouTubeSearchTool()]\n",
    "tools_string = f\"<tools>{''.join([format_tool_to_anthropic_function(t) for t in tools])}</tools>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e30dffe-bdf7-4cac-9497-422fb4257d87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 执行 Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf795969-db1c-4f26-a132-cc3c36660338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents.agent import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": \"找出 5 个老高与小茉的视频\",\n",
    "                       \"tools_string\": f\"<tools>{tools_string}</tools>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4442db1a-f060-4f64-99bd-40500b8168ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
